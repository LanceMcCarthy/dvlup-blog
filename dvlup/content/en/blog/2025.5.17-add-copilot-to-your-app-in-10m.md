---
title: 'Add Copilot to Your App in 10 Minutes'
date: 2024-12-25
draft: false
tags: ['copilot', 'AI', 'WinUI', 'winAppSdk', 'tutorial']
thumbnail: '/wp-content/uploads/2024/12/hugo-logo.png'
---

There has been a lot of news around generative AI and LLMs. As a traditional client app developer you might have wanted to add this capability to your app, but there's usually something that is a roadblock... you don't want to learn something new right now, you don't want to pay for a cloud service, or just don't have the time to invest in that one app. All of these excuses are hard to justify now you have the Windows Copilot Runtime APIs in the WinApp SDK. It's all on-device and can be done in a few lines of code.

Today I will show you how to add really good AI capability to your app in less time than your lunch hour... no cloud APIs, no REST calls, no custom onnx, no fees. Especialy when you have a bunch of AI scenarios available out-of-the-box.

## Gotchas

You might be asking, "okay, sounds amazing, why isn't everyone doing this? What's the catch?" The current qualification is that your user is on a Copilot+ PCs. However, lets be real, you wouldn't roll out these kinds of new features to all your users anyways. Why not add this capability to your app, even if its only for a small subset of users in the beginning?

So, let me show you how I did this to one of my apps and you can do the same (using my code if you like).

## Code Time

The reason any of this works is the Windows team has put a lot of work into making these [Copilot Runtime APIs](https://learn.microsoft.com/en-us/windows/ai/apis/) available in the WinApp SDK.

I won't take you through all the tiny details of setting up, you can learn that in the [Get started building an app with Windows Copilot Runtime APIs](https://learn.microsoft.com/en-us/windows/ai/apis/get-started?tabs=winget%2Cwinui) docs.

Once you have your environment setup, lets look at some app code.

In my case, though the [Image Description](https://learn.microsoft.com/en-us/windows/ai/apis/imaging#what-can-i-do-with-image-description) service would be perfect for my XKCD Viewer app

It's a strightforward desktop app, lets you view any xkcd comic and save/share favorites.

However, the app, but its natiure isn't inclusive of vision-impaired users. While yes, it's easy t read the text int he comic, there is a ton of nuance in the comic drawing that conveys the joke. 

 This is a perfect use case for having an intelligent model understand the context of the image, then describe it in a way that can be entertaining for a vision-impaired user!

