---
title: 'Add Copilot to Your App in 10 Minutes'
date: 2025-05-17
draft: false
tags: ['copilot', 'AI', 'WinUI', 'winAppSdk', 'tutorial']
thumbnail: '/wp-content/uploads/2025/copilot-runtime.png'
---

There has been a lot of news around generative AI and LLMs. As a traditional client app developer you might have wanted to add this capability to your app, but there's usually something that is a roadblock... you don't want to learn something new right now, you don't want to pay for a cloud service, or just don't have the time to invest in that one app. 

These excuses are hard to justify now you have the Windows Copilot Runtime APIs in the WinApp SDK; it's all available on-device and can be done in a few lines of code.

Today, I will show you how to add really good AI capability to your app in _less time than your lunch hour_... no cloud APIs or fees, no REST calls, and no custom onnx model. 

## What's the Catch?

You might be asking, "okay, sounds amazing, why isn't everyone doing this? What's the catch?" The current qualification is that your user is on a Copilot+ PCs. However, lets be real, you wouldn't roll out these kinds of new features to all your users anyways. 

Why not add this capability to your app, even if its only for a small subset of users in the beginning? Especialy when you have these AI capabilitites available out-of-the-box:

- **Phi Silica** - A local, ready-to-use language model. See Get started with Phi Silica.
- **AI text recognition** - Recognize text in images, and convert images/pdfs into searchable text. See Get started with AI text recognition.
- **AI Imaging** - Scale and sharpen images using AI (Image Super Resolution), as well as identify objects within an image (Image Segmentation). See Get Started with AI imaging.
- **Windows Studio Effects** - Apply AI effects to your device's device's built-in camera and microphone. See Windows Studio Effects Overview (Preview).

So, let me show you how I did this to one of my apps and you can do the same. In my case, for my XKCD Viewer app.

## Problem to Solve

I have an app, [Xkcd Viewer](https://apps.microsoft.com/detail/9PMCKHT7M93P?hl=en-us&gl=US&ocid=pdpshare), in the Microsoft Store. It's a strightforward desktop app that lets you view any xkcd comic and save/share favorites. It's completely open source, here's the repo => [github.com/LanceMcCarthy/XkcdViewer](https://github.com/LanceMcCarthy/XkcdViewer).

However, by its nature, the app isn't very inclusive of vision-impaired users. While yes, it's easy to read the caption text in the comic, there is *a ton* of nuance in the comic drawing that conveys the joke. 

This is a perfect use case for the [Image Description](https://learn.microsoft.com/en-us/windows/ai/apis/imaging#what-can-i-do-with-image-description) service, which understands the context of the image and then describes it in a way that can be entertaining for a vision-impaired user! It tries conveying the comedy behind the image, which is better than a plain screenreader.

## Code Time

The reason any of this works is the Windows team has put a lot of work into making these [Copilot Runtime APIs](https://learn.microsoft.com/en-us/windows/ai/apis/) available in the WinApp SDK. I won't take you through all the tiny details of setting up, use this doc to set up your dev environment => [Get started building an app with Windows Copilot Runtime APIs](https://learn.microsoft.com/en-us/windows/ai/apis/get-started?tabs=winget%2Cwinui) docs.

Once you are set up, a 10-minute modification to your app and add some great value. Let me walk you through code I used in my app. You can always refer to [src/XkcdViewer.Windows](https://github.com/LanceMcCarthy/XkcdViewer/tree/main/src/XkcdViewer.Windows) for the project code. 

First, you need to consider how you're going to "light up" these Copilot features for users on Copilot+ PCs. This is actually easy and given to you as a method in the SDK, I wrapped this is a simple `AppUtils.HasNpu()` call that returns true or false.

To make things more organized my project, I extended my normal MainViewModel class into two separate files [MainViwModel.cs](https://github.com/LanceMcCarthy/XkcdViewer/blob/main/src/XkcdViewer.Windows/MainViewModel.cs) and [MainViewModel.Copilot.cs](https://github.com/LanceMcCarthy/XkcdViewer/blob/main/src/XkcdViewer.Windows/MainViewModel.Copilot.cs). Then, at the top of the copilot side, I have a simple check to light up the Copilot features:

```csharp
private void InitializeCopilotCapabilities()
{
      // STEP 1 - If there is no NPU, back out and its business as usual.

      if (!AppUtils.HasNpu())
         return;

      // STEP 2 - However, if there is Copilot runtime, lets do a few things...

      // a. I shows the panel with Copilot controls
      CopilotCapVisibility = Visibility.Visible;

      // b. Populate the ComboBox with the available image description levels (the fault
      var levelsList = Enum.GetValues<ImageDescriptionScenario>();
      DescriptionLevels.AddRange(levelsList);

      // c. I preselect the one I think works best
      PreferredDescriptionLevel = DescriptionLevels.FirstOrDefault(n => n == ImageDescriptionScenario.DetailedNarration);
}
```
> The reason I chose `DetailedNarration` for the default narration type, is I think it provides the best results that attempt to convey the comedy/sarcasm.

Now, for the star of the show... look at [MainViewModel.Copilot.cs#L110](https://github.com/LanceMcCarthy/XkcdViewer/blob/d42038f3cbcaf2f62bb93857822e41a709f11ceb/src/XkcdViewer.Windows/MainViewModel.Copilot.cs#L110) where I ahve a `GetImageDescriptionAsync` task that takes in a the comic number and returns the text of the AI's descriuption.

Most of the logic is to download the image file and put it into a buffer, so let me bring you right to the important bits...

- On line 155 - I use `if (!ImageDescriptionGenerator.IsAvailable())` to check if Copilot is ready... if not, it gets it ready (I show progress to user, but this is a 1-time operation).
- On line 206, I call `imageDescriptionGenerator.DescribeAsync()` which gives the image to Copilot, and I get back a description (I show progress here, too, work happens every time).

Finally, because this feature is for vision-impaired, the text is played by the task `ReadAloudAsync` on line 255. This is just a normal MediaPlayer, not Copilot.

### More Code Resources

Here are some helpful items that will jumpstart your fun:

- Official Windows Copilot Runtime demos: A must-have
  - [Landing page](https://learn.microsoft.com/en-us/samples/microsoft/windowsappsdk-samples/windowscopilotruntime/)
  - [GitHub](https://github.com/microsoft/windowsappsdk-samples/tree/main/Samples/WindowsCopilotRuntime)
- Microsoft AI Dev Gallery: I highly recommend checking this out, the app will light up the Copilot runtime menu item on Copilot+ PCs
  - [MS Store](http://aka.ms/ai-dev-gallery-store)
  - [GitHub](https://github.com/microsoft/ai-dev-gallery)

## Conclusion

The main takeaway is it really only took me a few lines to add the capability to my project. Everything else around it is just window dressing... extra stuff to let the user to change the narration type and see progress indicators.

Here's a video of one of my early experiments, but there were many more generations; some were absolutely hillarious, others not so much. You will want to see what type works best for your needs.

{{< rawhtml >}} 
<video width=100% controls autoplay>
    <source src="/wp-content/uploads/2025/copilot-explains-xkcd.mp4" type="video/mp4">
    Your browser does not support the video tag.  
</video>
{{< /rawhtml >}}

If you have any questions or need help, don't hesitate to reach out to me [dvlup.com/about/](https://dvlup.com/page/about/) (or [bsky - @lance.boston](https://bsky.app/profile/lance.boston) | [x - @l_anceM](https://x.com/l_anceM) )

